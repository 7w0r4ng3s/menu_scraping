{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import io\n",
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "# from selenium import webdriver\n",
    "# from lxml import html\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of ucsc college 9 & 10 dining hall\n",
    "url = 'https://nutrition.sa.ucsc.edu/nutframe.asp?sName=UC+Santa+Cruz+Dining&locationNum=40&locationName=Colleges+Nine+%26+Ten+Dining+Hall&naFlag=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap the menu data from the webpage\n",
    "# since the menu data is cannot be scrapped from the html file directly\n",
    "# we have to make additional requests to get the frame page contents \n",
    "with requests.Session() as session:\n",
    "    response = session.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    for frame in soup.select(\"frameset frame\"):\n",
    "        frame_url = urljoin(url, frame[\"src\"])\n",
    "        response = session.get(frame_url)\n",
    "        frame_soup = BeautifulSoup(response.content, 'html.parser') \n",
    "        # print(frame_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract both the meal name and food name from html\n",
    "meal_name = frame_soup.find_all('div', attrs={'class': 'menusampmeals'})\n",
    "food_name = frame_soup.find_all('div', attrs={'class': 'menusamprecipes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Breakfast', 'Lunch', 'Dinner']\n",
      "Length:  3\n"
     ]
    }
   ],
   "source": [
    "# convert the name of the meal type in html form to a list form\n",
    "meal_type = [item.string for item in meal_name]\n",
    "print(meal_type)\n",
    "print('Length: ', len(meal_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Banana and Coconut Pancakes', 'Cage Free Scrambled Eggs', 'Chicken Mango Sausage', 'Coconut Syrup', 'Hard-boiled Cage Free Eggs', 'Natural BridgesTofu Scramble', 'Oatmeal Gluten-Free', 'Roasted Yukon Gold Potatoes', 'Steamed Rice', 'Chicken Tortilla Soup', 'Oven Roasted Allergen Free Chicken Thigh', 'Stuffed Shells in classic Marinara Sauce', 'Cheesy Garlic Bread Sticks', 'Steamed Seasonal Vegetables', 'Armenian Salad', 'BAR Middle Eastern', 'Beef and Lamb Gyro', 'Falafels', 'Lime Cilantro Basmati Rice', 'Tahini Sauce', 'Tzatziki Sauce', \"Chef's Special\", 'Oven Roasted Allergen Free Chicken Thigh', 'Cheese Pizza', 'Cilantro Flatbread with Red Onions and Mushrooms', 'BBQ Shredded Pork', 'Chicken Tenders', 'Condiments', 'Mac & Cheese', 'Mac and Cheese Bar', 'Roasted Vegetables', 'Vegan Macaroni & Cheese']\n",
      "Length:  32\n"
     ]
    }
   ],
   "source": [
    "# convert the food name in html form to a list form\n",
    "food_list = [item.string for item in food_name]\n",
    "print(food_list)\n",
    "print('Length: ', len(food_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Armenian Salad', 'BAR Middle Eastern', 'BBQ Shredded Pork', 'Banana and Coconut Pancakes', 'Beef and Lamb Gyro', 'Cage Free Scrambled Eggs', 'Cheese Pizza', 'Cheesy Garlic Bread Sticks', \"Chef's Special\", 'Chicken Mango Sausage', 'Chicken Tenders', 'Chicken Tortilla Soup', 'Cilantro Flatbread with Red Onions and Mushrooms', 'Coconut Syrup', 'Condiments', 'Falafels', 'Hard-boiled Cage Free Eggs', 'Lime Cilantro Basmati Rice', 'Mac & Cheese', 'Mac and Cheese Bar', 'Natural BridgesTofu Scramble', 'Oatmeal Gluten-Free', 'Oven Roasted Allergen Free Chicken Thigh', 'Roasted Vegetables', 'Roasted Yukon Gold Potatoes', 'Steamed Rice', 'Steamed Seasonal Vegetables', 'Stuffed Shells in classic Marinara Sauce', 'Tahini Sauce', 'Tzatziki Sauce', 'Vegan Macaroni & Cheese']\n",
      "Sorted length:  31\n"
     ]
    }
   ],
   "source": [
    "# In case of dupliate food name, the list should be converted to a set\n",
    "# sort\n",
    "food_list = sorted(list(set(food_list)))\n",
    "print(food_list)\n",
    "print('Sorted length: ', len(food_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Armenian Salad\n",
      "0\n",
      "BAR Middle Eastern\n",
      "0\n",
      "BBQ Shredded Pork\n",
      "1\n",
      "Banana and Coconut Pancakes\n",
      "1\n",
      "Beef and Lamb Gyro\n",
      "0\n",
      "Cage Free Scrambled Eggs\n",
      "1\n",
      "Cheese Pizza\n",
      "1\n",
      "Cheesy Garlic Bread Sticks\n",
      "1\n",
      "Chef's Special\n",
      "0\n",
      "Chicken Mango Sausage\n",
      "1\n",
      "Chicken Tenders\n",
      "1\n",
      "Chicken Tortilla Soup\n",
      "0\n",
      "Cilantro Flatbread with Red Onions and Mushrooms\n",
      "0\n",
      "Coconut Syrup\n",
      "0\n",
      "Condiments\n",
      "0\n",
      "Falafels\n",
      "0\n",
      "Hard-boiled Cage Free Eggs\n",
      "0\n",
      "Lime Cilantro Basmati Rice\n",
      "0\n",
      "Mac & Cheese\n",
      "1\n",
      "Mac and Cheese Bar\n",
      "1\n",
      "Natural BridgesTofu Scramble\n",
      "0\n",
      "Oatmeal Gluten-Free\n",
      "0\n",
      "Oven Roasted Allergen Free Chicken Thigh\n",
      "0\n",
      "Roasted Vegetables\n",
      "0\n",
      "Roasted Yukon Gold Potatoes\n",
      "1\n",
      "Steamed Rice\n",
      "1\n",
      "Steamed Seasonal Vegetables\n",
      "0\n",
      "Stuffed Shells in classic Marinara Sauce\n",
      "0\n",
      "Tahini Sauce\n",
      "0\n",
      "Tzatziki Sauce\n",
      "0\n",
      "Vegan Macaroni & Cheese\n",
      "0\n",
      "[0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "Preference length:  31\n"
     ]
    }
   ],
   "source": [
    "# preference list, labeled by myself\n",
    "# pref_1 = [1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0 ]\n",
    "# pref_2 = [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
    "# pref_3 = [0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
    "# pref_4 = [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n",
    "# pref_5 = [1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
    "pref_6 = []\n",
    "for i in food_list:\n",
    "    print(i)\n",
    "    preference = int(input())\n",
    "    pref_6.append(preference)\n",
    "print(pref_6)\n",
    "print('Preference length: ', len(pref_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current US/Pacific time:  2018-09-15\n"
     ]
    }
   ],
   "source": [
    "# timezone setting\n",
    "us_pacific = timezone('US/Pacific')\n",
    "time = datetime.now(us_pacific)\n",
    "us_time = time.strftime('%Y-%m-%d')\n",
    "print('Current US/Pacific time: ', us_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path:  /Users/7w0r4ng3s/Desktop/menu_scraping/data/2018-09-15.csv\n"
     ]
    }
   ],
   "source": [
    "# write the food list to a csv file\n",
    "path = '/Users/7w0r4ng3s/Desktop/menu_scraping/data/{}.csv'.format(us_time)\n",
    "print('Current path: ', path)\n",
    "path_2 = '/Users/7w0r4ng3s/Desktop/menu_scraping/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_csv: COMPLETED\n",
      "add_column_name: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "def write_data():\n",
    "    with open(path, \"w\") as output:\n",
    "        writer = csv.writer(output, lineterminator='\\n')\n",
    "        for key, val in zip(food_list, pref_6):\n",
    "            writer.writerow([key, val])\n",
    "    print('write_csv: COMPLETED')\n",
    "    # add index and column names\n",
    "    df = pd.read_csv(path, names=['food', 'pref'])\n",
    "    df.index.names = ['index']\n",
    "    df.to_csv(path)\n",
    "    print('add_column_name: COMPLETED')\n",
    "    \n",
    "write_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_data():\n",
    "#     # TODO: Figure out a way to get rid of the unnamed: 0 column\n",
    "#     # TODO: Modify merge_data() so that new data can be append to data.csv\n",
    "#     files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "\n",
    "#     merged = []\n",
    "\n",
    "#     for f in files:\n",
    "#         filename, ext = os.path.splitext(f)\n",
    "#         if ext == '.csv':\n",
    "#             read = pd.read_csv(f)\n",
    "#             merged.append(read)\n",
    "\n",
    "#     result = pd.concat(merged)\n",
    "#     result.to_csv('data.csv')\n",
    "    \n",
    "# merge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data():\n",
    "    df1 = pd.read_csv('Data.csv', index_col='index')\n",
    "    df1.index.names = ['index']\n",
    "    df2 = pd.read_csv(path, index_col='index')\n",
    "    df3 = df1.append(df2).reset_index()\n",
    "    df3 = df3.drop('index', 1).sort_values('food').reset_index().drop('index', 1)\n",
    "    df3.index.names = ['index']\n",
    "    df3.to_csv('Data.csv')\n",
    "    \n",
    "append_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
