{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import io\n",
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "# from selenium import webdriver\n",
    "# from lxml import html\n",
    "import csv\n",
    "from datetime import datetime, date, timedelta\n",
    "from pytz import timezone\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of ucsc college 9 & 10 dining hall\n",
    "url = 'https://nutrition.sa.ucsc.edu/nutframe.asp?sName=UC+Santa+Cruz+Dining&locationNum=40&locationName=Colleges+Nine+%26+Ten+Dining+Hall&naFlag=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap the menu data from the webpage\n",
    "# since the menu data is cannot be scrapped from the html file directly\n",
    "# we have to make additional requests to get the frame page contents \n",
    "with requests.Session() as session:\n",
    "    response = session.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    for frame in soup.select(\"frameset frame\"):\n",
    "        frame_url = urljoin(url, frame[\"src\"])\n",
    "        response = session.get(frame_url)\n",
    "        frame_soup = BeautifulSoup(response.content, 'html.parser') \n",
    "        # print(frame_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract both the meal name and food name from html\n",
    "meal_name = frame_soup.find_all('div', attrs={'class': 'menusampmeals'})\n",
    "food_name = frame_soup.find_all('div', attrs={'class': 'menusamprecipes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Breakfast', 'Lunch', 'Dinner']\n",
      "Length:  3\n"
     ]
    }
   ],
   "source": [
    "# convert the name of the meal type in html form to a list form\n",
    "meal_type = [item.string for item in meal_name]\n",
    "print(meal_type)\n",
    "print('Length: ', len(meal_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cage Free Scrambled Eggs', 'Ham Steaks', 'Hard-boiled Cage Free Eggs', 'Natural BridgesTofu Scramble', 'Oatmeal Gluten-Free', \"Potatoes O'Brien\", 'Steamed Rice', 'Texas French Toast', 'Tomato Bisque Soup', 'Oven Roasted Allergen Free Chicken Thigh', 'Teriyaki Chicken Shoyu', 'Veggie Fried Rice', 'Cheese Pizza', 'Cilantro Flatbread with Red Onions and Mushrooms', 'Pepperoni Pizza', 'Steamed Rice', 'Steamed Seasonal Vegetables', 'Atomic Cheese Sauce', 'BAR Boardwalk Burgers', 'Bacon', 'Bread Bun', 'Burger Bar #1 Condiments', 'Burger Beef', 'Chili con Carne', 'Onion Rings', 'Sauteed Mushrooms', 'Vegan Malibu Burger', 'Fried Chicken', 'Oven Roasted Allergen Free Chicken Thigh', 'Steamed Seasonal Vegetables', 'Red Skin Mashed Potatoes', 'Bar Pasta', 'Cheese Ravioli', 'Cheesy Garlic Bread Sticks', 'Condiments', 'Creamy Alfredo Sauce', 'Marinara Sauce', 'Penne']\n",
      "Length:  38\n"
     ]
    }
   ],
   "source": [
    "# convert the food name in html form to a list form\n",
    "food_list = [item.string for item in food_name]\n",
    "print(food_list)\n",
    "print('Length: ', len(food_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Atomic Cheese Sauce', 'BAR Boardwalk Burgers', 'Bacon', 'Bar Pasta', 'Bread Bun', 'Burger Bar #1 Condiments', 'Burger Beef', 'Cage Free Scrambled Eggs', 'Cheese Pizza', 'Cheese Ravioli', 'Cheesy Garlic Bread Sticks', 'Chili con Carne', 'Cilantro Flatbread with Red Onions and Mushrooms', 'Condiments', 'Creamy Alfredo Sauce', 'Fried Chicken', 'Ham Steaks', 'Hard-boiled Cage Free Eggs', 'Marinara Sauce', 'Natural BridgesTofu Scramble', 'Oatmeal Gluten-Free', 'Onion Rings', 'Oven Roasted Allergen Free Chicken Thigh', 'Penne', 'Pepperoni Pizza', \"Potatoes O'Brien\", 'Red Skin Mashed Potatoes', 'Sauteed Mushrooms', 'Steamed Rice', 'Steamed Seasonal Vegetables', 'Teriyaki Chicken Shoyu', 'Texas French Toast', 'Tomato Bisque Soup', 'Vegan Malibu Burger', 'Veggie Fried Rice']\n",
      "Sorted length:  35\n"
     ]
    }
   ],
   "source": [
    "# In case of dupliate food name, the list should be converted to a set\n",
    "# sort\n",
    "food_list = sorted(list(set(food_list)))\n",
    "print(food_list)\n",
    "print('Sorted length: ', len(food_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preference list, labeled by myself\n",
    "# pref_1 = [1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0 ]\n",
    "# pref_2 = [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
    "# pref_3 = [0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
    "pref_4 = [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current US/Pacific time:  2018-09-10\n"
     ]
    }
   ],
   "source": [
    "# timezone setting\n",
    "us_pacific = timezone('US/Pacific')\n",
    "time = datetime.now(us_pacific)\n",
    "us_time = time.strftime('%Y-%m-%d')\n",
    "print('Current US/Pacific time: ', us_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path:  /Users/7w0r4ng3s/Desktop/menu_scraping/data/2018-09-10.csv\n"
     ]
    }
   ],
   "source": [
    "# write the food list to a csv file\n",
    "path = '/Users/7w0r4ng3s/Desktop/menu_scraping/data/{}.csv'.format(us_time)\n",
    "print('Current path: ', path)\n",
    "path_2 = '/Users/7w0r4ng3s/Desktop/menu_scraping/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data():\n",
    "    with open(path, \"w\") as output:\n",
    "        writer = csv.writer(output, lineterminator='\\n')\n",
    "        for key, val in zip(food_list, pref_4):\n",
    "            writer.writerow([key, val])\n",
    "    print('write_csv: COMPLETED')\n",
    "\n",
    "    df = pd.read_csv(path, names=['food', 'pref'])\n",
    "    df.index.names = ['index']\n",
    "    df.to_csv(path)\n",
    "    print('add_column_name: COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_csv: COMPLETED\n",
      "add_column_name: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "write_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data():\n",
    "    # TODO: Figure out a way to get rid of the unnamed: 0 column\n",
    "    # TODO: Modify merge_data() so that new data can be append to data.csv\n",
    "    files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "\n",
    "    merged = []\n",
    "\n",
    "    for f in files:\n",
    "        filename, ext = os.path.splitext(f)\n",
    "        if ext == '.csv':\n",
    "            read = pd.read_csv(f)\n",
    "            merged.append(read)\n",
    "\n",
    "    result = pd.concat(merged)\n",
    "    result.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data():\n",
    "    df1 = pd.read_csv('Data.csv', index_col='index')\n",
    "    df2 = pd.read_csv(path, index_col='index')\n",
    "    df3 = df1.append(df2).reset_index()\n",
    "    df3.index.names = ['index']\n",
    "    df3 = df3.drop('index', 1).sort_values('food').reset_index().drop('index', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
