{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import io\n",
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "# from selenium import webdriver\n",
    "# from lxml import html\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of ucsc college 9 & 10 dining hall\n",
    "url = 'https://nutrition.sa.ucsc.edu/nutframe.asp?sName=UC+Santa+Cruz+Dining&locationNum=40&locationName=Colleges+Nine+%26+Ten+Dining+Hall&naFlag=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap the menu data from the webpage\n",
    "# since the menu data is cannot be scrapped from the html file directly\n",
    "# we have to make additional requests to get the frame page contents \n",
    "with requests.Session() as session:\n",
    "    response = session.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    for frame in soup.select(\"frameset frame\"):\n",
    "        frame_url = urljoin(url, frame[\"src\"])\n",
    "        response = session.get(frame_url)\n",
    "        frame_soup = BeautifulSoup(response.content, 'html.parser') \n",
    "        # print(frame_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract both the meal name and food name from html\n",
    "meal_name = frame_soup.find_all('div', attrs={'class': 'menusampmeals'})\n",
    "food_name = frame_soup.find_all('div', attrs={'class': 'menusamprecipes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Breakfast', 'Lunch', 'Dinner']\n",
      "Length:  3\n"
     ]
    }
   ],
   "source": [
    "# convert the name of the meal type in html form to a list form\n",
    "meal_type = [item.string for item in meal_name]\n",
    "print(meal_type)\n",
    "print('Length: ', len(meal_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blueberry Pancakes', 'Cage Free Scrambled Eggs', 'Crispy Bacon', 'Hard-boiled Cage Free Eggs', 'Natural BridgesTofu Scramble', 'Oatmeal Gluten-Free', 'Steamed Rice', 'Tator Tots', 'Chicken Tortilla Soup', 'Memphis Meatloaf', 'Oven Roasted Allergen Free Chicken Thigh', 'Cheese Pizza', 'Pepperoni Pizza', 'Roma Pesto Pizza', 'Red Skin Mashed Potatoes', 'Steamed Seasonal Vegetables', 'Bar Indian', 'Bengan Aloo', 'Condiments', 'Lime Cilantro Basmati Rice', 'Madras Chicken', 'Masala Vegetables', 'Original Naan', 'Asian Pork Spareribs', 'Oven Roasted Allergen Free Chicken Thigh', 'Vegetable Lo Mein', 'Roasted Vegetables', 'Authentic Spanish Rice', 'Baja Fish Tacos', 'Baja Taco Bar', 'Charro Beans', 'Chipotle Seitan Fajitas', 'Corn Tortillas', 'Pork Al Pastor']\n",
      "Length:  34\n"
     ]
    }
   ],
   "source": [
    "# convert the food name in html form to a list form\n",
    "food_list = [item.string for item in food_name]\n",
    "print(food_list)\n",
    "print('Length: ', len(food_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asian Pork Spareribs', 'Authentic Spanish Rice', 'Baja Fish Tacos', 'Baja Taco Bar', 'Bar Indian', 'Bengan Aloo', 'Blueberry Pancakes', 'Cage Free Scrambled Eggs', 'Charro Beans', 'Cheese Pizza', 'Chicken Tortilla Soup', 'Chipotle Seitan Fajitas', 'Condiments', 'Corn Tortillas', 'Crispy Bacon', 'Hard-boiled Cage Free Eggs', 'Lime Cilantro Basmati Rice', 'Madras Chicken', 'Masala Vegetables', 'Memphis Meatloaf', 'Natural BridgesTofu Scramble', 'Oatmeal Gluten-Free', 'Original Naan', 'Oven Roasted Allergen Free Chicken Thigh', 'Pepperoni Pizza', 'Pork Al Pastor', 'Red Skin Mashed Potatoes', 'Roasted Vegetables', 'Roma Pesto Pizza', 'Steamed Rice', 'Steamed Seasonal Vegetables', 'Tator Tots', 'Vegetable Lo Mein']\n",
      "Sorted length:  33\n"
     ]
    }
   ],
   "source": [
    "# In case of dupliate food name, the list should be converted to a set\n",
    "# sort\n",
    "food_list = sorted(list(set(food_list)))\n",
    "print(food_list)\n",
    "print('Sorted length: ', len(food_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preference list, labeled by myself\n",
    "# pref_1 = [1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0 ]\n",
    "# pref_2 = [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
    "# pref_3 = [0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
    "# pref_4 = [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n",
    "pref_5 = [1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current US/Pacific time:  2018-09-11\n"
     ]
    }
   ],
   "source": [
    "# timezone setting\n",
    "us_pacific = timezone('US/Pacific')\n",
    "time = datetime.now(us_pacific)\n",
    "us_time = time.strftime('%Y-%m-%d')\n",
    "print('Current US/Pacific time: ', us_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path:  /Users/7w0r4ng3s/Desktop/menu_scraping/data/2018-09-11.csv\n"
     ]
    }
   ],
   "source": [
    "# write the food list to a csv file\n",
    "path = '/Users/7w0r4ng3s/Desktop/menu_scraping/data/{}.csv'.format(us_time)\n",
    "print('Current path: ', path)\n",
    "path_2 = '/Users/7w0r4ng3s/Desktop/menu_scraping/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data():\n",
    "    with open(path, \"w\") as output:\n",
    "        writer = csv.writer(output, lineterminator='\\n')\n",
    "        for key, val in zip(food_list, pref_5):\n",
    "            writer.writerow([key, val])\n",
    "    print('write_csv: COMPLETED')\n",
    "    # add index and column names\n",
    "    df = pd.read_csv(path, names=['food', 'pref'])\n",
    "    df.index.names = ['index']\n",
    "    df.to_csv(path)\n",
    "    print('add_column_name: COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_csv: COMPLETED\n",
      "add_column_name: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "write_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data():\n",
    "    # TODO: Figure out a way to get rid of the unnamed: 0 column\n",
    "    # TODO: Modify merge_data() so that new data can be append to data.csv\n",
    "    files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "\n",
    "    merged = []\n",
    "\n",
    "    for f in files:\n",
    "        filename, ext = os.path.splitext(f)\n",
    "        if ext == '.csv':\n",
    "            read = pd.read_csv(f)\n",
    "            merged.append(read)\n",
    "\n",
    "    result = pd.concat(merged)\n",
    "    result.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data():\n",
    "    df1 = pd.read_csv('Data.csv', index_col='index')\n",
    "    df1.index.names = ['index']\n",
    "    df2 = pd.read_csv(path, index_col='index')\n",
    "    df3 = df1.append(df2).reset_index()\n",
    "    df3 = df3.drop('index', 1).sort_values('food').reset_index().drop('index', 1)\n",
    "    df3.index.names = ['index']\n",
    "    df3.to_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
