{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os\n",
    "import io\n",
    "import bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "# from selenium import webdriver\n",
    "# from lxml import html\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of ucsc college 9 & 10 dining hall\n",
    "url = 'https://nutrition.sa.ucsc.edu/nutframe.asp?sName=UC+Santa+Cruz+Dining&locationNum=40&locationName=Colleges+Nine+%26+Ten+Dining+Hall&naFlag=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrap the menu data from the webpage\n",
    "# since the menu data is cannot be scrapped from the html file directly\n",
    "# we have to make additional requests to get the frame page contents \n",
    "with requests.Session() as session:\n",
    "    response = session.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    for frame in soup.select(\"frameset frame\"):\n",
    "        frame_url = urljoin(url, frame[\"src\"])\n",
    "        response = session.get(frame_url)\n",
    "        frame_soup = BeautifulSoup(response.content, 'html.parser') \n",
    "        # print(frame_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract both the meal name and food name from html\n",
    "meal_name = frame_soup.find_all('div', attrs={'class': 'menusampmeals'})\n",
    "food_name = frame_soup.find_all('div', attrs={'class': 'menusamprecipes'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Breakfast', 'Lunch', 'Dinner']\n",
      "Length:  3\n"
     ]
    }
   ],
   "source": [
    "# convert the name of the meal type in html form to a list form\n",
    "meal_type = [item.string for item in meal_name]\n",
    "print(meal_type)\n",
    "print('Length: ', len(meal_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cage Free Scrambled Eggs', 'French Waffles', 'Hard-boiled Cage Free Eggs', 'Natural BridgesTofu Scramble', 'Oatmeal Gluten-Free', \"Potatoes O'Brien\", 'Sausage Patties', 'Steamed Rice', 'Chicken Noodle Soup', 'Oven Roasted Allergen Free Chicken Thigh', 'Peanut Kung Pao Chicken', 'Peanut Kung Pao Vegetables', 'Sticky Rice', 'Roasted Seasonal Vegetables', 'Armenian Salad', 'Beef and Lamb Gyro', 'Falafels', 'Tabouleh Salad', 'Tahini Sauce', 'Tzatziki Sauce', 'French Fries', 'Turkey Corn Dogs', 'BBQ Beef Brisket', 'Oven Roasted Allergen Free Chicken Thigh', 'Cheese Pizza', 'Pepperoni Pizza', 'Veggie Supreme Pizza', 'Baked Potatoes with Toppings', 'Roasted Corn', 'Steamed Seasonal Vegetables', 'Condiments', 'Grilled Huli Huli Chicken', 'Hawaiian Bar', 'Potato Mac Salad', 'Spicy Vegan Chicken and Broccoli Stir Fry', 'Sticky Rice']\n",
      "Length:  36\n"
     ]
    }
   ],
   "source": [
    "# convert the food name in html form to a list form\n",
    "food_list = [item.string for item in food_name]\n",
    "print(food_list)\n",
    "print('Length: ', len(food_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Armenian Salad', 'BBQ Beef Brisket', 'Baked Potatoes with Toppings', 'Beef and Lamb Gyro', 'Cage Free Scrambled Eggs', 'Cheese Pizza', 'Chicken Noodle Soup', 'Condiments', 'Falafels', 'French Fries', 'French Waffles', 'Grilled Huli Huli Chicken', 'Hard-boiled Cage Free Eggs', 'Hawaiian Bar', 'Natural BridgesTofu Scramble', 'Oatmeal Gluten-Free', 'Oven Roasted Allergen Free Chicken Thigh', 'Peanut Kung Pao Chicken', 'Peanut Kung Pao Vegetables', 'Pepperoni Pizza', 'Potato Mac Salad', \"Potatoes O'Brien\", 'Roasted Corn', 'Roasted Seasonal Vegetables', 'Sausage Patties', 'Spicy Vegan Chicken and Broccoli Stir Fry', 'Steamed Rice', 'Steamed Seasonal Vegetables', 'Sticky Rice', 'Tabouleh Salad', 'Tahini Sauce', 'Turkey Corn Dogs', 'Tzatziki Sauce', 'Veggie Supreme Pizza']\n",
      "Sorted length:  34\n"
     ]
    }
   ],
   "source": [
    "# In case of dupliate food name, the list should be converted to a set\n",
    "# sort\n",
    "food_list = sorted(list(set(food_list)))\n",
    "print(food_list)\n",
    "print('Sorted length: ', len(food_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Armenian Salad\n",
      "0\n",
      "BBQ Beef Brisket\n",
      "1\n",
      "Baked Potatoes with Toppings\n",
      "1\n",
      "Beef and Lamb Gyro\n",
      "1\n",
      "Cage Free Scrambled Eggs\n",
      "1\n",
      "Cheese Pizza\n",
      "1\n",
      "Chicken Noodle Soup\n",
      "1\n",
      "Condiments\n",
      "0\n",
      "Falafels\n",
      "0\n",
      "French Fries\n",
      "1\n",
      "French Waffles\n",
      "1\n",
      "Grilled Huli Huli Chicken\n",
      "0\n",
      "Hard-boiled Cage Free Eggs\n",
      "0\n",
      "Hawaiian Bar\n",
      "0\n",
      "Natural BridgesTofu Scramble\n",
      "0\n",
      "Oatmeal Gluten-Free\n",
      "0\n",
      "Oven Roasted Allergen Free Chicken Thigh\n",
      "0\n",
      "Peanut Kung Pao Chicken\n",
      "1\n",
      "Peanut Kung Pao Vegetables\n",
      "0\n",
      "Pepperoni Pizza\n",
      "0\n",
      "Potato Mac Salad\n",
      "0\n",
      "Potatoes O'Brien\n",
      "0\n",
      "Roasted Corn\n",
      "0\n",
      "Roasted Seasonal Vegetables\n",
      "0\n",
      "Sausage Patties\n",
      "1\n",
      "Spicy Vegan Chicken and Broccoli Stir Fry\n",
      "0\n",
      "Steamed Rice\n",
      "1\n",
      "Steamed Seasonal Vegetables\n",
      "0\n",
      "Sticky Rice\n",
      "1\n",
      "Tabouleh Salad\n",
      "0\n",
      "Tahini Sauce\n",
      "0\n",
      "Turkey Corn Dogs\n",
      "0\n",
      "Tzatziki Sauce\n",
      "0\n",
      "Veggie Supreme Pizza\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# preference list, labeled by myself\n",
    "# pref_1 = [1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0 ]\n",
    "# pref_2 = [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
    "# pref_3 = [0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
    "# pref_4 = [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n",
    "# pref_5 = [1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
    "pref_6 = []\n",
    "for i in food_list:\n",
    "    print(i)\n",
    "    preference = int(input())\n",
    "    pref_6.append(preference)\n",
    "print(pref_6)\n",
    "len('Preference length: ', pref_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current US/Pacific time:  2018-09-12\n"
     ]
    }
   ],
   "source": [
    "# timezone setting\n",
    "us_pacific = timezone('US/Pacific')\n",
    "time = datetime.now(us_pacific)\n",
    "us_time = time.strftime('%Y-%m-%d')\n",
    "print('Current US/Pacific time: ', us_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path:  /Users/7w0r4ng3s/Desktop/menu_scraping/data/2018-09-12.csv\n"
     ]
    }
   ],
   "source": [
    "# write the food list to a csv file\n",
    "path = '/Users/7w0r4ng3s/Desktop/menu_scraping/data/{}.csv'.format(us_time)\n",
    "print('Current path: ', path)\n",
    "path_2 = '/Users/7w0r4ng3s/Desktop/menu_scraping/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_csv: COMPLETED\n",
      "add_column_name: COMPLETED\n"
     ]
    }
   ],
   "source": [
    "def write_data():\n",
    "    with open(path, \"w\") as output:\n",
    "        writer = csv.writer(output, lineterminator='\\n')\n",
    "        for key, val in zip(food_list, pref_6):\n",
    "            writer.writerow([key, val])\n",
    "    print('write_csv: COMPLETED')\n",
    "    # add index and column names\n",
    "    df = pd.read_csv(path, names=['food', 'pref'])\n",
    "    df.index.names = ['index']\n",
    "    df.to_csv(path)\n",
    "    print('add_column_name: COMPLETED')\n",
    "    \n",
    "write_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data():\n",
    "    # TODO: Figure out a way to get rid of the unnamed: 0 column\n",
    "    # TODO: Modify merge_data() so that new data can be append to data.csv\n",
    "    files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "\n",
    "    merged = []\n",
    "\n",
    "    for f in files:\n",
    "        filename, ext = os.path.splitext(f)\n",
    "        if ext == '.csv':\n",
    "            read = pd.read_csv(f)\n",
    "            merged.append(read)\n",
    "\n",
    "    result = pd.concat(merged)\n",
    "    result.to_csv('data.csv')\n",
    "    \n",
    "merge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data():\n",
    "    df1 = pd.read_csv('Data.csv', index_col='index')\n",
    "    df1.index.names = ['index']\n",
    "    df2 = pd.read_csv(path, index_col='index')\n",
    "    df3 = df1.append(df2).reset_index()\n",
    "    df3 = df3.drop('index', 1).sort_values('food').reset_index().drop('index', 1)\n",
    "    df3.index.names = ['index']\n",
    "    df3.to_csv('Data.csv')\n",
    "    \n",
    "append_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
